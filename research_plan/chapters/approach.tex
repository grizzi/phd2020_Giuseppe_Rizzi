\section{Approach}
\label{sec:Approach}

This section outlines the proposal approach, methodology and research gaps currently existing for each subproblem. A solution to robust manipulation of articulated objects consists of perception and control algorithms designed to work together. The high level driving hypothesis to solve the manipulation problem is:
\begin{displayquote}
\textit{Physics simulation and photorealistic rendering can be used as core technology for real-time control, estimation and modeling for object manipulation}
\end{displayquote}   
We believe that the potential of simulation engines (both for physical interaction and rendering) has not been fully exploited in the current research. Nevertheless, contemporary simulators are fast and accurate enough to replace analytical model while rendering engine afford photorealistic results. They can not only be used for offline synthesis and validation but also to generate manipulation behaviors and robust perception in real-time. The real-time offers the following advantages:
\begin{itemize}
\item Closed-loop control keep small the deviation of the simulation from the current observed state
\item The improved real-time estimate of model parameters (e.g joints' position and orientation) can dynamically change the simulation
\item Detection algorithm can directly act in a virtual rendered scene which replicate the current simulated environment zeroing the \emph{sim-to-real} gap.
\end{itemize}
On the other hand, a full-scene simulation and rendering is computationally expensive. Therefore it is of utmost importance to come up with new algorithmic solutions that require little data or can cope with limited computational resources. As an example, one could decide to focus perception only on the object to be interacted with and reduce collision checks to the hand (gripper) and the few interaction points.  
The building blocks of the proposed approach build on top of this core component and consists of:
\begin{itemize}
\item closed-loop physics-aware control
\item affordances based perception
\item active model estimation und uncertainty reduction
\end{itemize}
In the rest of this section, a overview of the underlying assumptions are provided and a description of each subgoal and methodology. 

\paragraph{Methodology} each proposed solution is first evaluated in simulation and then on the real hardware consisting of the Royal-Panda mobile manipulator platform. The robot consists of a 7-DoF Franka Emika arm mountend on the holonomic Clearpath Ridgeback base. 

\paragraph{Assumptions} in this research plan the following assumptions are made:
\begin{itemize}
\item the object category is recognized prior to manipulation
\item manipulation can be solved in a non-prehensile manner: grasping is not required
\item sensing modalities are RGB-D images, point clouds, proprioceptive data and wrist-mounted wrench measurements 
\item articulated objects are restricted to the class of open loop kinematic chains consisting of a combination of revolute and/or prismatic joints
\end{itemize} 

List of the algorithms and software packages to use:
- Raisim and Sapien
- pinocchio
- torch
- Panda platform (hardware)

\begin{itemize}
	\item \emph{What approach will be used?}
	\item \emph{Why is the approach promising?}
	\item \emph{What are the expected results?}
\end{itemize}

\subsection{Physics Aware Control}
The literature generally distinguishes between planning and control algorithms. In this research proposal control is the process of genereting a reference signal that the robot can track and brings the system into the state where the manipulation task is completed. A typical example is a velocity-controlled manipulator which has to open a door. A control algorithm is then in charge of generating the sequence of velocity values that allows the robot to interact with the door and move it to the open state. This definition is general enough to encompass various approaches. The velocity, for example, can be tracked by another low-level controller which compensates for gravity and Coriolis effects and commands robot torques. The controller could be split into an intermediate step where a reference end-effector trajectory is computed and this is then converted to low-level velocity signals. The proposed approach consists in planning directly in the joint velocity space as this allows to consider additional objectives such as joint limits and self-collisions. Furthermore, a low-level control layer which converts velocity references to torques is always used. In fact, tuning the low-level PD gains let us define a desired compliant behavior avoiding high interaction wrenches with the stiff environment. 
A cost function is then used as a proxy to inform the controller about the completeness of the task. In the running example, this could be the squared distance from the current door's joint angle to the one corresponding to the open position. 
Directly optimizing such a cost as a function in the robot action space is extremely complex. In fact, the mapping between the optimization variables (velocities) and the cost is highly non-linear. The mapping goes through the full whole body dynamics and switching interactions that happen between the robot and the door. For this reason, we resort to gradient free methods. They come at the cost of being less sample efficient compared to gradient-based methods. Gradient-free methods rely on sampling input-state trajectories in simulation in order to drive the system towards optimality (see Sec.~\ref{sec:related_work_control}).

\subsubsection{Research gap and relation to previous works}
Using a fully fledged simulation backend exploits the fact that basic physcial concepts (e.g, distinct objects cannot occupy the same space, gravity applies mass-dependent force on objects, friction and kinematic constraints) provide strong prior knowledge for manipulation tasks~\cite{kroemer2019review}. In this first part of the work a practical receding horizon algorithm that achieves real-time whole-body control of a mobile manipulator using only a laptop CPU is proposed. This work is based on Model Predictive Path Integral control (MPPI)~\cite{williams_information_2017}, which is used as the underlying sampling-based controller for whole-body coordination and control. Several algorithmic elements enable the controller to achieve performant results, often requiring fewer than 100 rollouts. The main contribution is a regularization of our sampling exploration by means of a momentum update. This is inspired by the Bayesian inference viewpoint of~\cite{lambert_stein_2020}, which showes that the choice of exploration noise has the effect of tuning the gradient step size of the path integral update. The benefits of this sampling scheme are twofold, it can aid in escaping local minima while also damping strong oscillations in the optimal policy. Raisim phisics engine is used for fast and accurate simulation~\cite{raisim} while the pinocchio library~\cite{pinocchioweb} is used for rigid body dynamics modeling. The goal of this subtask is to verity the following hypothesis
\begin{displayquote}
\textit{Gradient-free methods are applicable with limited results and in real-time for whole body mobile manipulation.}
\end{displayquote}

\subsection{Results}
The developed algorithm is able to control a complex system in real-time without the need for massive parallel computation. To demonstrate the applicability and effectiveness of this approach, several ablation studies are performed in simulation on kinematic and dynamical manipulators. The full algorithm is then deployed on the \textit{RoyalPanda} platform for a target reaching and door opening task. An open source implementation of the solution is readily available at \url{https://git.io/Jtda7}. The results support the original hypothesis and encourage to deploy the algorithm to more challenging systems such as aerial vehicles.

\subsection{Manipulation Affordances}
As mentioned in the previous section, control requires a reward signal to know which states are closer to the target state. In practice, the true objective is to manipulate the object to a target configuration but we do not care too much about the intermediate robot and object states. The cost then is generally an educated guess about this reward signal and can generally impose a structure not needed or even subpotimal for the manipulation problem. Consider the problem of turning a handwheel valve. The final objective (valve being turned) can be achieved in vary different ways. For example one could grasp the wheel from the side or just apply a tangential push force to the ribs that connect the wheel to the shaft. It is argued here that designing a cost function that enforce a preference for one or the other approach is suboptimal for autonomous manipulation. Instead, the cost could be related to the concept of \emph{affordances}. The controller can then be informed about more generic interesting interaction regions.

\subsubsection{Research gap and relation to previous works}
The concept of \emph{affordances} for manipulation has been explored in many recent perception works. They mainly differ in the representation of object affordace as interaction points~\cite{gao2021kpam}, interaction regions~\cite{nagarajan2019grounded} or dense interaction likelihood and orientation maps~\cite{mo2021where2act}. Most of this works do not highlight the importance and applicability of the resulting perception pipeline for manipulation control. Furthermore an agreement on what it the optimal representation of affordances for object manipulation. In this part of the research proposal the aim is to combine affordances with control. The goal of this subtask is to verity the following hypothesis
\begin{displayquote}
\textit{Affordances allow to better exploit the structure in manipulation tasks with respect to fixed manipulation strategies.}
\end{displayquote}
The controller can try to bring the robot close to \emph{high-affordance} points. Note that this task can be hard or even unfeasible for traditional gradient based methods, while the sampling based algorithm so far developed lends itself well to this objective. 
Furthermore, a novel concept of affordances will be explored, by introducing, for example haptic information. Intuitively, human do not only know by experience where to act on object but how. The latest prior can be expressed in terms of interaction orientation and expected wrench profiles (e.g. pulling vs pushing force). The goal of this second part of the project is to verify the following research hypothesis
\begin{displayquote}
\textit{Affordances describing haptic information are more descriptive then purely geometrical based affordances.}
\end{displayquote} 
In this task the SAPIEN simulators will be used since it integrates a comprehensive set of articulated objects normally found in households, provides ground truth segmenation and photo-realistic rendering~\cite{Xiang_2020_SAPIEN}. 

\subsection{Perceptive Manipulation}
A fundamental aspects to take into consideration for object manipulation is model estimation and the associated \emph{hepistemic uncertainty} which is the uncertainty about the model parameters. Recurring to the running example, even knowing the high level task (open or close a door), we might not know the geometrical and physical properties of the object such as size, weight, friction, hinge position and orientation. While affordances provide a good prior for control and sampling based method provide a good local approximation of optimal control, we miss a component in the whole pipeline that can account for the uavoidable uncertainty. In this final part of the work the research goal is to incorporate uncertainty in the manipulation framework so far developed. Forceful interaction, also known as \emph{peceptive manipulation}~\cite{bohg2017interactive} can be used to validate hypothesis about the articulation model. 

- Using affordances as a way to optimize for uncertainty: e.g: affordance tells that a point can be pushed: then pushgin it will create some motion that in turn can be used to fit a model
- In order to connect with the rendering engin: assume that we have a series of images. This stream can be matched against the output from a rendering pipeline to see which underlying model better represents the visual information (better develop this idea).
- Possibility of using the optical flow (G.Sanding vision during Action)

- Concept of virtual affordance: points in the surrounding of an object have affordance as well: for example when we approach an object we do not go straight to the handle but rather try to approach is from the side. This could mean that we think to start the push action close to the object, not exactly at the object. 	
- Haptic Input
- Generally what is perceived is not fed back to the simulation 

Can we use affordances and control as described before to reduce uncertainty. In other words, can we use interactive perception in simulation to learn (as a supervision signal) a type of affordance which is telling us what is the expected uncertainty about a specific action at a specific point? How can we incorporate this uncertainty in the control structure. Provide (think of) an example: 
Certain properties of objects such as kinematic constraints, can only be accuratevely estimated by observing the outcome of an interaction. As an example, interacting with a door can reduce the uncertainty on the course initial estimation of the hinge position and orientation. This process is called \emph{interactive perception}.  

Choosing the action that maximimzes a estimation criteria is known as \emph{active perception}. 
What do we want to better estimate/perceive? Affordances, model parameters?
 
\subsubsection{Research gap and relation to previous works}
Most of the nowadays perception algorithms try to semantically annotate a one-shot passive view of the scene relying on minimal prior assumptions and knowledge. These requirements render the considered perception problems underconstrained and threby make them very hard to solve~\cite{bohg2017interactive}.   
Works dealing with articulated object pose estimation~\cite{li2020category} (aggiungere altri) show promising results but inaccuracy from single-shot detection is still too large to deploy this estimate for modeling and control. 

- ABC methods 
- \cite{pathak2019self} using discrepancy between outcomes (variance) as instrinsic reward
- test overleaf sync