\section{Introduction}
\label{sec:Introduction}


\begin{itemize}
	\item \emph{What is this research plan about?}
\end{itemize}

There is growing interest in deploying autonomous systems in every-day life. Robots have the power to enhance productivity while relieving human labor from repetitive and dangerous tasks. In many applications, these tasks consist of a physical interaction between the autonomous agent and the surrounding environment. Opening a door, pushing a button, turning a switch are just a few of the recurring interaction instances. We refer to the autonomous execution of them with the umbrella term of \emph{autonomous manipulation}. Complex manipulation is demanded in assistive service in the healthcare domain~\cite{cooper2020ari} , agriffods~\cite{duckett2018agricultural} and industrial inspection and maintainance~\cite{lattanzi2017review}. This research proposal contributes to advance the state of the art of autonomous manipulation as part of the Horizon 2020 framework and Piloting European project~\cite{eu-piloting-2020}. Recent successful applications (cite something) in search and rescue have shown that robots are a priceless alternative to life threatening human operations. With this motivation, the project aims to successfully deploy ground and aerial unmanned vehicles for industrial maintainance and inspection. 
- To mention: manipulation of objects make the system underactuated independentlyh from the dofs of the robot 
\begin{itemize}
    \item \emph{What are the (high-level) research gaps?}
\end{itemize}

Manipulation is hard. This research field encompass hardware and software design. The former focuses on finding new layouts, morphologies and actuation principles that bring robots closer to the human dexterous and mobility capabilities. In this research proposal, the goal is to find new and more effecitve algorithmic solutions to manipulation on robotic platforms readily available. Complexity in robotic manipulation arises from the combination of multiple research sub-topics, namely \emph{perception}, \emph{modeling}, \emph{control} and \emph{planning}. The core limitation found in the literature consists in addressing the problems found in each of this fields separately. We claim that in order to push further the boundaris of \emph{autonomous manipulation}, a joint effort is needed. 

\paragraph{Perception:} The real world is too complex to expect an accurate model of the enviroment and the objects which are contained in it. For this reason we need to perceive the scene. Autonomous manipulation requires a denser and interaction rich information which is not provided by these models. We need perception to provide a broad appreciation of the scene but also to provide high-resolution information, including knowledge of the contact locations and forces exchanged~\cite{mason2018toward}. Nevertheless, perception is often threated separately from control. As a consequence, perception systems are developed whose representation of the world is not optimal from the control perspective. In the last decade, perception systems have focused on tasks such as classification~\citep{redmon2016you}, semantic segmentation~\cite{badrinarayanan2017segnet}, generative modeling~\citep{karras2019stylebased} and pose estimation~\cite{xiang2017posecnn}. 

\paragraph{Control and Planning:} we can define manipulation as the act of changing the state of the environment (object) by exchanging interaction forces with it. Interaction consists of point-to-point, point-to-plane, continuous and discontinous contacts. Furthermore exchanged wrenches could be high under wrong modeling assumptions and damage the robot and the surrounding environment. In order to avoid high interaction wrenches with a rigid environment we need a compliant control strategy which can reason about the scene physics. This is a complex task which is generally decoupled into a separate planning and control stages.  


\paragraph{Uncertainty: } the geometry of the scene can be measured only at the accuracy allowed by the visual sensors and perception pipeline. The modeling of the environment and its physical properties can also be inaccurate. Consider the apparently easy task of turning a crank. The required motion required is a simple circle. The problem is, where exactly should the robot produce the circle? We can do our best to estimate the crankâ€™s position, but we will never get it exactly right \citep{mason2018toward}. Uncertainty is often threated as a metric in the state estimation pipeline rather then a variable to actively account for during control. So generally control validation is performed with ground-truth information or the architecture is designed such that it complies with a small degree of uncertainty. Do human account on perfect knowledge of the environment? We observe that we do not but we are still able to perform a myriads of complex interaction tasks. We must deduce that environment knowledge is improved on the "fly" and we use the unconscious knowledge of uncertainty to perceive, plan and control as a whole. As an example, what would a human do when trying to turn a light switch in the shadow? She would probably reach the visible wall next to the door and scrap the surface until sensing a switch-shaped object. We need perception and control algorithms that actively take uncertainty into consideration in order to achieve robust manipulation capabilities under hard sensing conditions.   
\newline
We can summarize the identified gaps for autonomous manipulation in the following:
\begin{itemize}
\item \textbf{Suboptimal scene representation} from visual inputs.
\item \textbf{Rigid plan-and-act control} architecture
\item \textbf{Lack of reasoning about uncerteinty} in perception and modeling. 
\end{itemize}

\begin{itemize}
    \item \emph{What is the overall goal?}
\end{itemize}

The overall goal is to come up with a tight perception and control framework which is able to address robustly the problem of autonomous robotic manipulation alleviating the limitation of the current approaches and providing scalability, applicability to the real platform while staying as general as possible.
