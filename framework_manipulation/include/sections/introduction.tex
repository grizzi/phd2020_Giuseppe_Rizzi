\section{Introduction} \label{sec:introduction}
% Vision

There is a growing interest in deploying autonomous systems in unstructured environments to perform complex manipulation tasks for different applications like assistive service in the healthcare domain~\cite{cooper2020ari}, agrifoods~\cite{duckett2018agricultural}, and industrial inspection and maintenance~\cite{lattanzi2017review}. Mobile manipulator robots present a compelling choice to tackle these problems since they combine an unconstrained workspace with highly dexterous interaction capabilities. However, to fully exploit these capabilities, systems require planning and control algorithms that can generate fast, accurate, and coordinated reactive whole-body motions that account for multiple potential contacts with the environment. 

\subsection{Related Works}

% Existing methods
While traditional ``plan-and-act'' frameworks break down such tasks into subproblems that are easier to solve (e.g. reach, grasp, pull)~\cite{Murali2020}, they do not offer fast replanning, which is crucial for mobile manipulation in dynamic and uncertain environments.

With the recent advancements in artificial intelligence, reinforcement learning (RL) is a promising method to solve a range of robotic control tasks, including manipulation~\cite{finn2016deep}, as they learn an end-to-end representation of the optimal policy. However, real-world applications of RL typically require training times that are not practical for physical hardware and suffer from the well-known \textit{sim-to-real} gap~\cite{chebotar2019closing}. 
On the other side of the spectrum, Model Predictive Control (MPC) has gained broad interest in the robotics community thanks to its ability to deal with input constraints and task objectives by solving a multivariate optimization problem or using the \textit{principle of optimality}. 
MPC has been successfully applied to aerial robots~\cite{brunner2020trajectory}, autonomous racing~\cite{liniger2015optimization}, legged locomotion~\cite{grandia2019frequency}, and whole-body control~\cite{minniti2019whole}. 
Nevertheless, MPC requires a model that is locally differentiable with respect to the input and the state~\cite{buchli2017optimal}. On the other hand, manipulation tasks involve changes in the contact state causing sharp discontinuities in both the cost and system dynamics, thus directly violating the differentiability requirements. 


\begin{figure}[t]
\centering
\includegraphics[trim={0 0 0 100},clip,width=0.9\columnwidth]{framework_manipulation/figures/hardware/system_figure.pdf}
\caption{\textit{RoyalPanda}, a 10-DOF mobile manipulator while performing a door opening task.} \label{fig:royal_panda}
\end{figure}

% Performance : sampling control
Recently, sampling-based methods have emerged and advanced in theory and applications~\cite{lee_aggressive_2020,abraham_model-based_2020,williams_information_nodate,williams_information_2017,rajamaki_augmenting_2017}. 
In contrast to traditional MPC, sampling methods stem from a probabilistic interpretation of the control problem. 
Rather than solving a complex optimization problem, they rely on sampling system trajectories, referred to as \textit{rollouts}, and ``weighting'' them according to the cumulative cost so that only favorable trajectories survive the iterative sampling process. The only requirement is that it is possible to forward simulate the system evolution. This has been exploited to control camera motions for target tracking in drone racing~\cite{lee_aggressive_2020}, robot arm motions for manipulation tasks~\cite{abraham_model-based_2020}, and for generating aggressive driving maneuvers such as drifting~\cite{williams_information_nodate, williams_information_2017}. 

% Gap 
Demonstrations on real systems involving different physical interactions (e.g. a robot arm opening a drawer~\cite{abraham_model-based_2020}) have typically only been shown by breaking down the multi-contact task into stages and enforcing constraints when switching between them. 
This can limit the control envelope of the system and sacrifices solution optimality. For example, it is common practice to fix the gripper orientation between successive reach and pull stages and perform manipulation under a rigid grasp. In the presence of uncertainty and tracking errors, this often leads to high contact forces and dangerous behaviors.

% Safety : Barrier functions
In order to avoid safety-critical configurations often additional cost terms are formulating. While penalizing unsafe paths, they do not prohibit them. As a consequence, constraints fulfillment merely relies on sampling ``safe" trajectories. 
Recently \emph{Control Barrier Functions} (CBFs) have been introduced as a means to constrain the system to a safe set. The safe set defines the locus where all safety requirements are met, e.g. no self-collision happens and joint limits are fulfilled. CBFs are expressed as affine inequality constraints in the control input that, when satisfied point-wise in the candidate safe set, imply forward invariance of the set and hence safety \cite{ames2016control}.  This control method has been successfully deployed in safety-critical applications such as Adaptive Cruise Control and Lane Keeping \cite{vahidi2003research}, segway stabilization \cite{gurriet2018towards} and human-robot collaboration \cite{benzi2021optimization}.

% Stability : passivity
Last but not least, sampling-based methods do not ensure stability which, especially during autonomous interaction, is as important as performance. In this regard, we are interested in a stable interaction with an \emph{a priori} poorly known environment. This lack of knowledge might come from sensing limitations or a model mismatches. \emph{Passivity theory} has drawn attention in recent years as a way to analyze the stability of a controlled system. Intuitively, a passive system cannot produce more energy than the one it is provided with. A rather new approach to ensure \emph{passivity} is to use an auxiliary virtual system called \emph{energy tank} as a storing element containing the maximum energy budget available to perform the task. Energy tanks have been successful deployed in many robotics applications such as for impedance controllers with time-varying stiffness \cite{schindlbeck2015unified}, force-impedance control \cite{shahriari2018valve}, and lately with CBFs for controlling a robotic arm \cite{benzi2021optimization}.

\subsection{Contributions}

We propose a practical and robust receding horizon algorithm that achieves real-time whole-body control of a mobile manipulator using only a laptop CPU. Our work is based on an iterative sampling of control trajectories. Safety and stability are ensured through a sequential optimization problem that finds the closest policy to the optimized one, which enforces constraints and passivity of the autonomous system.

Our main contribution is a new framework for mobile manipulation which combines tools from stochastic optimization, safety-critical control, and passivity theory.
% Results
To demonstrate the applicability and effectiveness of this approach, we perform several ablation studies in simulation on a dynamical manipulator and deploy the full algorithm on our \textit{RoyalPanda} platform (a 7-DOF Franka Emika Panda arm mounted on the holonomic Clearpath Ridgeback base, \fig\ref{fig:royal_panda}) for a target reaching and door opening task. An open source implementation of our solution is provided at \url{https://git.io/Jtda7}.

In summary, the contributions of the present work are as follows:
\begin{enumerate}
    \item A framework for safe interaction-aware receding horizon control of a mobile manipulator,
    \item practical insights and a power-aware cost formulation focused on mobile manipulation tasks,
    \item an experimental evaluation of the effectiveness of the approach and of the contribution of each algorithmic component and hardware experiments showing its applicability to the real platform,
    \item an open source implementation of the proposed method including a multi-threaded sampling-based controller and an efficient quadratic program for addressing kinematic and dynamic constraints.
    \end{enumerate}

\subsection{Overview}

The remainder of the paper is organized as follows. In 
\sect \ref{sec:formulation} the manipulation problem is first formulated. In \sect \ref{sec:theory} we review the main theoretical background introducing receding horizon sampling-based control, the concept of barrier functions and energy tanks. These tools are combined in a unified control method in \sect \ref{sec:control_method}. We then evaluate the overall method in \sect \ref{sec:experiments} and conclude with hardware experiments. 

\add{I should stress that we find ZBF and Pass as good fit as they are safety modules working at the same level (joint velocities) as the sampling, thus they meld very well together.}